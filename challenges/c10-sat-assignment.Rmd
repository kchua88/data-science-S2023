---
title: "SAT and College Grades"
author: "(Your name here)"
date: 2020-
output:
  github_document:
    toc: true
prerequisites:
  - e-vis00-basics
editor_options: 
  markdown: 
    wrap: 72
---

*Purpose*: How do we apply hypothesis testing to investigating data? In
this challenge you'll practice using hypothesis testing tools to make
sense of a dataset.

*Reading*: - [Harvard Study Says SATs Should Be Optional: Here's
Why](https://www.csmonitor.com/USA/USA-Update/2016/0120/Harvard-study-says-SATs-should-be-optional.-Here-s-why)
(Optional); easy-to-read news article on colleges going SAT-free -
[Norm-Referenced Tests and Race-Blind
Admissions](https://cshe.berkeley.edu/publications/norm-referenced-tests-and-race-blind-admissions-case-eliminating-sat-and-act-university)
(Optional); technical report on relationship between the SAT/ACT and
non-academic factors

*Credit*: This is based on a [case
study](http://onlinestatbook.com/2/case_studies/sat.html) originally
prepared by Emily Zitek, with data collected through the research of
Thomas MacFarland.

```{r setup}
library(tidyverse)
library(readxl)
library(broom)
library(modelr)
library(rsample)
library(MASS)
```

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics
define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category    | Needs Improvement                                                                                                | Satisfactory                                                                                                               |
|--------------|----------------------------|-------------------------------|
| Effort      | Some task **q**'s left unattempted                                                                               | All task **q**'s attempted                                                                                                 |
| Observed    | Did not document observations, or observations incorrect                                                         | Documented correct observations based on analysis                                                                          |
| Supported   | Some observations not clearly supported by analysis                                                              | All observations clearly supported by analysis (table, graph, etc.)                                                        |
| Assessed    | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support      |
| Specified   | Uses the phrase "more data are necessary" without clarification                                                  | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability                                 | Code sufficiently close to the [style guide](https://style.tidyverse.org/)                                                 |

## Due Date

<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due **at midnight**
before the day of the class discussion of the challenge. See the
[Syllabus](https://docs.google.com/document/d/1qeP6DUS8Djq_A0HMllMqsSqX3a9dbcx1/edit?usp=sharing&ouid=110386251748498665069&rtpof=true&sd=true)
for more information.

*Background*: Every year about 2 million students take the Scholastic
Aptitude Test (SAT). The exam is
[controversial](http://www.nea.org/home/73288.htm) but [extremely
consequential](https://www.csmonitor.com/2004/0518/p13s01-legn.html).
There are many claims about the SAT, but we're going to look at just
one: Is the SAT predictive of scholastic performance in college? It
turns out this is a fairly complicated question to assess---we'll get an
introduction to some of the complexities.

# Obtain the Data

<!-- -------------------------------------------------- -->

### **q1** Visit the [SAT and College GPA](http://onlinestatbook.com/2/case_studies/sat.html) case study page, scroll to the bottom, and click the `Open Data with Excel` button. This will allow you to download an `xls` file. Save the file to your `data` folder, load the data as `df_sat`, and perform your "first checks" against these data. Answer the questions below:

```{r q1-task}
## TODO:
df_sat <- read_csv('./data/sat.csv')


## TODO: Do your "first checks"

df_sat
glimpse(df_sat)

```

**Observations**:

-   Fill in the following "data dictionary"

| Column     | Meaning                                |
|------------|----------------------------------------|
| `high_GPA` | High school grade point average        |
| `math_SAT` | Math SAT score                         |
| `verb_SAT` | Verbal SAT score                       |
| `comp_GPA` | Computer science grade point average   |
| `univ_GPA` | Overall university grade point average |

-   What information do we have about these students?
    -   Overall, these ar e105 students who graduated from a state
        university with a B.S. in computer science. We have their
        individual GPA's, math SAT score, verbal SAT score, Computer
        science grade point average, and their overall university grade
        point average.
-   What kinds of information *do we not have* about these students?
    -   We don't have their personal background, gender, name, how many
        classes they took, etc.
-   Based on these missing variables, what possible effects could be
    present in the data that we would have *no way of detecting*?
    -   We don't have their economic background - this could increase
        someone's SAT score and high school GPA if they were able to be
        tutored and retake the SAT multiple times.

# Analysis with Hypothesis Testing

<!-- ----------------------------------------------------------------------- -->

We're going to use two complementary approaches to analyze the data, the
first based on hypothesis testing of correlation coefficients, and the
second based on fitting a regression model and interpreting the
regression coefficients.

To simplify the analysis, let's look at a composite SAT score:

```{r compute-composite}
## NOTE: No need to edit this
df_composite <-
  df_sat %>%
  mutate(both_SAT = math_SAT + verb_SAT)

df_composite
```

## View 1: Correlations

<!-- ----------------------------------------------------------------------- -->

### **q2** Create a *single* plot that shows `univ_GPA` against *both* `high_GPA` and `both_SAT`. Visually compare the two trends.

*Hint*: One way to do this is to first *pivot* `df_composite`.

```{r q2-task}
## TODO:
df_composite %>%
  pivot_longer(
    cols = c('high_GPA', 'both_SAT'),
    names_to = 'score_type',
    values_to = 'score' ) %>%
  ggplot(aes(univ_GPA, score)) + 
  geom_point() + 
  facet_grid(rows = vars(score_type), scales = "free")
```

**Observations**:

-   What relationship do `univ_GPA` and `both_SAT` exhibit?
    -   There seems to be a positive correlation between univ_GPA and
        both_SAT for university GPA's higher than a 3.0.
-   What relationship do `univ_GPA` and `high_GPA` exhibit?
    -   There seems to be a positive correlation between univ_GPA and
        high_GPA for university GPA's higher than a 3.0.

### Hypothesis Testing with a Correlation Coefficient

<!-- ------------------------- -->

We can use the idea of hypothesis testing with a correlation
coefficient. The idea is to set our null hypothesis to the case where
there is no correlation, and test to see if the data contradict that
perspective. Formally, the null (H0) and alternative (HA) hypotheses
relating to a correlation coefficient between two variables `X, Y` are:

$$\text{H0: } \text{Corr}[X, Y] = 0$$

$$\text{HA: } \text{Corr}[X, Y] \neq 0$$

The R function `cor.test` implements such a hypothesis test under the
assumption that `X, Y` are both normally distributed. First, let's check
to see if this assumption looks reasonable for our data.

### **q3** Plot histograms for `both_SAT, high_GPA, univ_GPA`. Which---if any---of the variables look approximately normally distributed.

```{r q3-task}
df_composite %>%
ggplot() +
  geom_histogram(mapping = aes(x = both_SAT), binwidth = 20)

df_composite %>%
ggplot() +
  geom_histogram(mapping = aes(x = high_GPA), binwidth = 0.1)

df_composite %>%
ggplot() +
  geom_histogram(mapping = aes(x = univ_GPA), binwidth = 0.1)
```

**Observations**:

-   To what extent does `both_SAT` look like a normal distribution?
    -   Both_SAT doesn't look like a normal distribution because it
        seems to have generally even distribution among the SAT score as
        opposed to a bell curve.
-   To what extent does `high_GPA` look like a normal distribution?
    -   High_GPA almost looks like a normal distribution except that
        there is a large dip in the middle at the 3.0 GPA.
-   To what extent does `univ_GPA` look like a normal distribution?
    -   Univ_GPA does not look like a normal distribution because it is
        skewed left and not symmetric. There are more higher GPA scores
        than lower ones.

Keep in mind your findings as you complete q4.

### **q4** Use the function `cor.test()` to construct confidence intervals for `corr[high_GPA, univ_GPA` and `corr[both_SAT, univ_GPA]`. Answer the questions below.

```{r q4-task}
## TODO: Use the function cor.test() to test the correlations between
##       high_GPA and univ_GPA, as well as between
##       both_SAT and univ_GPA


high_GPA <- df_composite %>% 
  pull(high_GPA)
univ_GPA <- df_composite %>% 
  pull(univ_GPA)
both_SAT <- df_composite %>% 
  pull(both_SAT)

cor.test(high_GPA, univ_GPA)
cor.test(both_SAT, univ_GPA)


```

**Observations**:

-   Which correlations are significantly nonzero?
    -   Both univ_GPA vs. high_GPA and univ_GPA vs. both_SAT are
        significantly nonzero because both their confidence intervals do
        not include 0.
-   Which of `high_GPA` and `both_SAT` seems to be more strongly
    correlated with `univ_GPA`?
    -   high_GPA seems to be more strongly coorelated with univ_GPA with
        a coorelation coefficient of 0.78 as opposed to 0.68 for
        both_SAT and univ_GPA. This is supported by the confidence
        intervals for high_GPA including higher values than both_SAT.
-   How do the results here compare with the visual you created in q2?
    -   The coorelation coefficients make sense with the visual from q2
        since by looking at the plot, univ_GPA is more strongly
        coorelated with high GPA. However, it is not super strongly
        coorelated - so therefore the coorelation coefficient is 0.78 as
        opposed to being closer to 1.
-   Based on these results, what can we say about the predictive
    capabilities of both `high_GPA` and `both_SAT` to predict
    `univ_GPA`?
    -   Since it is more strongly coorelated with a higher coorelation
        coefficient, high_GPA can predict univ_GPA more strongly than
        the both_SAT score.

Finally, let's use the bootstrap to perform the same test using
*different* assumptions.

### **q5** Use the bootstrap to approximate a confidence interval for `corr[high_GPA, univ_GPA`. Compare your results---both the estimate and confidence interval---to your results from q4.

```{r q5-task}
## TODO: Use the bootstrap to compute a confidence interval for corr[high_GPA, univ_GPA]
n_bootstrap <- 1000
bootstrap_cor <- numeric(n_bootstrap)
for (i in 1:n_bootstrap) {
  sample_id <- sample(length(high_GPA), replace = TRUE)
  sample_high_GPA <- high_GPA[sample_id]
  sample_univ_GPA <- univ_GPA[sample_id]
  bootstrap_cor[i] <- cor(sample_high_GPA, sample_univ_GPA)
}
# Compute confidence interval
lower_ci <- quantile(bootstrap_cor, 0.025)
upper_ci <- quantile(bootstrap_cor, 0.975)
est <- quantile(bootstrap_cor, 0.5)
lower_ci
upper_ci
est
```

**Observations**:

-   How does your estimate from q5 compare with your estimate from q4?
    -   The estimate from q5 is on average 0.783 compared to the 0.78
        estimate from q4 is very similar.
-   How does your CI from q5 compare with your CI from q4?
    -   The Cl from q5 is (0.69535 - 0.853135) and q4
        (0.6911690-0.8449761) is also around the same.

*Aside*: When you use two different approximations to compute the same
quantity and get similar results, that's an *encouraging sign*. Such an
outcome lends a bit more credibility to the results.

## View 2: Modeling

<!-- ------------------------- -->

Correlations are useful for relating two variables at a time. To study
the relationship among more variables we can instead use a fitted model.
Using a model, we can also help assess whether it is *worthwhile* to
measure a variable.

To begin, let's first split the data into training and validation sets.

```{r split}
## NOTE: No need to edit
set.seed(101)

df_train <-
  df_composite %>%
  rowid_to_column() %>%
  slice_sample(n = 80)

df_validate <-
  df_composite %>%
  rowid_to_column() %>%
  anti_join(
    .,
    df_train,
    by = "rowid"
  )
```

### Hypothesis Testing with a Model

<!-- ------------------------- -->

We can combine the ideas of hypothesis testing with a model. Using a
model, we can express our hypotheses in terms of the model parameters.
For instance, if we were interested in whether $X$ has an affect on $Y$,
we might set up a model:

$$Y_i = \beta X_i + \epsilon_i$$

With the hypotheses:

$$\text{H0}: \beta = 0$$

$$\text{HA}: \beta \neq 0$$

In this case, we're testing for whether $X$ has a significant effect on
$Y$. Let's apply this idea to relating the variables `univ_GPA` and
`high_GPA`. Luckily R has built-in tools to construct a confidence
interval on the $\beta$'s in a regression [1]; we'll simply use those
tools rather than do it by hand.

### **q6** Fit a linear model predicting `univ_GPA` with the predictor `both_SAT`. Assess the model to determine how effective a predictor `both_SAT` is for `univ_GPA`. Interpret the resulting confidence interval for the coefficient on `both_SAT`.

```{r q6-task}

fit_basic <-
  lm(
    data = df_train,
    formula = univ_GPA ~ both_SAT
  )
## NOTE: The following computes confidence intervals on regression coefficients

fit_basic %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
tibble(
  err_Train = mse(fit_basic, df_train),
  err_Validate = mse(fit_basic, df_validate))
```

**Observations**:

-   What is the confidence interval on the coefficient of `both_SAT`? Is
    this coefficient significantly different from zero?
    -   The confidence interval on the coefficient of both_SAT is from
        0.001715376 to 0.003415381. The coefficient is statistically
        significantly different from 0 because the interval excludes 0.
-   By itself, how well does `both_SAT` predict `univ_GPA`?
    -   Since the coefficient is very close to 0, both_SAT is not a good
        predictor of univ_GPA.

Remember from `e-model03-interp-warnings` that there are challenges with
interpreting regression coefficients! Let's investigate that idea
further.

### **q7** Fit a model predicting `univ_GPA` using both `high_GPA` and `both_SAT`. Compare the prediction accuracy and hypothesis test results.

```{r q7-task}
## TODO: Fit and assess models with predictors both_SAT + high_GPA, and high_GPA alone

fit_both <-
  lm(
    data = df_train,
    formula = univ_GPA ~ both_SAT + high_GPA
  )
## NOTE: The following computes confidence intervals on regression coefficients
fit_both %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
tibble(
  err_Train = mse(fit_both, df_train),
  err_Validate = mse(fit_both, df_validate))
```

**Observations**:

-   How well do these models perform, compared to the one you built in
    q6?
    -   The high_GPA model has a coefficient of 0.570 which is
        significantly different from 0. The both_SAT model had a
        coefficient close to 0 which shows that it cannot predict
        univ_GPA as well.
-   What is the confidence interval on the coefficient of `both_SAT`
    when including `high_GPA` as a predictor?? Is this coefficient
    significantly different from zero?
    -   The confidence interval on the coefficient of both_SAT including
        high_GPA as a predictor is between 0.2989814792 to 0.842138715.
        The coefficient is statistically significantly different from 0
        because the confidence interval excludes 0.
-   How do the hypothesis test results compare with the results in q6?
    -   The results from q7 show that high_GPA included as a predictor
        in univ_GPA is a better fit. The model error (mean squared
        error) is also lower than the result in q6 when using just
        both_SAT as a predictor for univ_GPA.

## Synthesize

<!-- ------------------------- -->

Before closing, let's synthesize a bit from the analyses above.

### **q8** Using the results from all previous q's, answer the following questions.

**Observations**:

-   Between `both_SAT` and `high_GPA`, which single variable would you
    choose to predict `univ_GPA`? Why?
    -   high_GPA because there is a significant difference with its
        coefficient from 0 compared to both_SAT used as a predictor.
-   Is `both_SAT` an effective predictor of `univ_GPA`? What specific
    pieces of evidence do you have in favor of `both_SAT` being
    effective? What specific pieces of evidence do you have against?
    -   No, both_SAT is not an effective predictor of univ_GPA because
        its coefficient is close to 0 when we tried to linearly fit that
        with univ_GPA. However, if we want to try to argue that it is
        effective at being a predictor, we can say that there could be a
        very slight correlation with univ_GPA and both_SAT since its
        coefficient's confidence interval from 0.001715476 to
        0.003414381 doesn't include 0.

# End Notes

<!-- ----------------------------------------------------------------------- -->

[1] There are also assumptions underlying this kind of testing, for more
information see this [Wiki
article](https://en.wikipedia.org/wiki/Linear_regression#Assumptions).
